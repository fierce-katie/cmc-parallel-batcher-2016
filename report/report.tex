\documentclass[oneside,final,14pt]{extreport}
\usepackage[T1,T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{vmargin}
\usepackage{textcomp}
\usepackage{graphicx}
\usepackage{diagbox}
\newcommand*{\No}{\textnumero}
\setpapersize{A4}
\setmarginsrb{3cm}{2cm}{1cm}{2cm}{0pt}{0mm}{0pt}{13mm}
\usepackage{indentfirst}
\sloppy
\setcounter{page}{2}
\clubpenalty = 10000
\widowpenalty = 10000

\begin{document}
{\let\clearpage\relax \chapter*{Постановка задачи}}

В задаче требовалось реализовать параллельный алгоритм для вычислительной
системы с распределённой памятью, обеспечивающий разбиение узлов сетки
на домены методом рекурсивной координатной бисекции. Число вершин в каждом
домене должно отличаться не более чем на единицу.

На вход программе подаётся размер сетки ($n_1$, $n_2$) и количество доменов~$k$. Узлы сетки
представлены структурой \texttt{Point}, которая имеет следующий вид:
\begin{verbatim}
    Point {
        float coord[2];
        int index;
    };
\end{verbatim}
Сетка представляется в программе как массив из таких структур длины $n_1~*~n_2$.

Координаты вершины однозначно определяются индексами $i$ и $j$. Смежными с
ней считаются вершины с индексами $(i - 1, j)$, $(i, j - 1)$, $(i + 1, j)$
и $(i, j + 1)$. Таким образом, заданная сетка топологически эквивалентна
прямоугольной.

Программа должна выводить в файл результат декомпозиции, указывая для
каждой точки её индексы, координаты и домен, в который она была распределена.
Также должно быть подсчитано количество разрезанных рёбер.

\chapter*{Метод решения}

\section*{Инициализация сетки}

Для того чтобы перед началом работы на каждом процессоре было одинкаковое количество
элементов, при необходимости
исходный массив дополняется фиктивными элементами типа \texttt{Point} с
отрицательным значением индекса. Распределение фиктивных элементов происходит
при инициализации массивов на каждом из процессоров.

Наличие фиктивного элемента на процессоре зависит от его номера (\texttt{rank}).
Количество процессоров, на которых нет фиктивных элементов, равно остатку от
деления количества элементов в исходном массиве на количество процессоров.
Если номер процессора меньше этого значения, то инициализируются все элементы
соответствующего фрагмента массива. В противном случае, последний элемент
массива считается фиктивным, и его поле \texttt{index} инициализируется
отрицательным значением, а кординаты~--- константой \texttt{FLT\_MAX}
(максимальное число типа \texttt{float}).

Распределение элементов реализовано в функции \texttt{init\_points}
(см.~приложение~\ref{app:par}).

\section*{Метод рекурсивной координатной бисекции для одного процессора}

Основная идея последовательного алгоритма состоит в следующем: на каждом
шаге алгоритма сетка разбивается на две части в определённой пропорции по
одной из осей, затем рекурсивно разбивается каждая из этих частей~\cite{baraban}.
Пропорция вычисляется таким образом, чтобы количество элементов в каждой
части отличалось не более чем на единицу.

Пусть имется сетка (массив) из $n$ вершин, которую нужно разбить на $k$ доменов.
Функция, реализующая алгоритм рекурсивной координатной бисекции, принимает
следующие аргументы: адрес начала массива точек, сдвиг для текущего фрагмента,
количество точек в текущем фрагменте, наименьший номер домена, в который ещё
не были распределены точки (далее будем называть его темущим доменом),
и общее количество доменов, на которое необходимо разбить текущий фрагмент.

Базой рекурсии являются два случая. Во-первых, если массив состоит из одного
эелемента, то этот элемент распределяется в текущий домен. Во-вторых,
если текущий фрагмент нужно разбить на один домен ($k = 1$), то все
элементы из фрагменты распределяются в этот домен.

В общем случае фрагмент массива сначала сортируется по одной из координатных
осей. В программе используется алгоритм сортировки слиянием (функция
\texttt{dsort},~\cite{sortbaraban}). Затем фрагмент разбивается на две части
в отношении
$\frac{k_1}{k_2}$, где $k_1 = \frac{k + 1}{2}$, $k_2 = k - k_1$.
В соответствии с этой пропорцией вычисляются новые значения для количества
элементов в новых фрагментах и их сдвиг относительно начала массива.
Эти фрагменты разбиваются по другой оси на $k_1$ и $k_2$ доменов соответственно
с помощью рекурсивных вызовов.

Рeализация описанного последовательного алгоритма приведена в
приложении~\ref{app:seq} (функция \texttt{bisect}).

\section*{Метод рекурсивной координатной бисекции для нескольких процессоров}

В параллельном алгоритме рекурсивной координатной бисекции распределение точек
по доменам происходит в два этапа: разбитие вершин по процессорам и
разбитие вершин на домены на каждом процессоре с помощью описанного
выше последовательного алгоритма декомпозиции.

Базой рекурсии также являются два случая. Если общее число доменов равно
одному, то из фрагмента массива на процессоре удаляются фиктивные элементы,
а оставшимся точкам приписывается номер текущего домена. Если число
процессов, участвующих в разбиении, равно единице, то происходит удаление
фиктивных элементов и вызывается функция \texttt{bisect\_seq},
в которой реализован последовательный алгоритм разбиения.

В общем случае работа алгоритма начинается с определения оси, вдоль которой
будет отсортирован массив точек. На каждом процессоре определяются локальные
значения локального минимума и максимума по каждой координате, затем
глобальные значения (с использованием функции \texttt{MPI\_Allreduce}) и
протяжённость осей. Сортировка происходит по оси с большей протяжённостью.
Для процессоров, участвующих в разбиении на данном этапе, строится сеть слияния
Бэтчера и производится сортировка текущего фрагмента массива на этих
процессорах.

Далее вычисляесят пропорция $\frac{k_1}{k_2}$, где $k_1 = \frac{k + 1}{2}$,
$k_2 = k - k_1$, а $k$~--- количество доменов. В том же отношении
количесвто элементов массива в текущем фрагменте разбивается на две части:
в первой $n_1 = n * \frac{k_1}{k}$ элементов, а во второй $n_2 = n - n_1$.
Определяется номер среднего элемента, и номер процессора, на котором
этот элемент находится. Эти значения равны остатку и целой части деления
$n_1$ на количество элементов на каждом процессоре. Процессоры делятся на две
части: $[0 .. middle\_proc - 1]$ и $[middle\_proc .. procs]$, где
$middle\_proc$~--- номер процессора, на котором находится средний элемент,
$procs$~--- количество процессоров, участвующих в разбиении.

Перед рекурсивным вызовом элементы массива перераспределяются по процессорам
в каждой группе. Для того, чтобы разбить процессоры на групппы используется
функция \texttt{MPI\_Comm\_split}. На процессоре с номером $middle\_proc$
находится средний элемент массива. Все элементы слева от него отправляются
на процессоры с меньшими номерами порциями одинакового размера. При
необходимости добавляются фиктивные элементы. Процессоры с меньшими номерами
получают эти элементы и добавляют в свои фрагменты массива. После
перераспределения элементов производится рекурсивный вызов функции.

Особого внимания требует случай $middle\_proc = 0$. Если следовать
предложенному выше алгоритму бисекции, то окажется, что
в первой группе процессоры отсутствуют. Поэтому в данном случае считается,
что в первой группе находится только процессор с нулевым рангом.
Элементы фрагмента массива на этом процессре, находящиеся справа от среднего,
рассылаются порциями одинаковой длины на все процессоры во второй группе.
Они, в свою очередь, добавляют эти элементы в свои фрагменты массива.
После этого на всех процессорах происходит рекурсивный вызов функции.

Описанный алгоритм реализован в функции \texttt{bisect} в приложении
\ref{app:par}. Локальная бисекция на домены реализована в функции
\texttt{bisect\_seq}.

\section*{Вывод результата}

Для записи в файл используется функция \texttt{MPI\_File\_write\_ordered}.
Первый процессор записывает в файл размеры сетки, количество доменов и
разрезанных рёбер. Затем каждый процессор записывает свой фрагмент массива
структур типа \texttt{Domain}:
\begin{verbatim}
    struct Domain {
        int i;
        int j;
        float coord[2];
        int domain;
    };
\end{verbatim}
Эта вспомогательная структура введена для
удобства записи в файл, подсчёта разрезанных рёбер и отладки программы. В ней явно указаны требуемые для
вывода поля: индексы точки, её координаты и номер домена. Перед выводом
результата на каждом процессоре из массива точек \texttt{proc\_points}
формируется массив из вспомогательных структур \texttt{proc\_domains}, при этом
фиктивные эелементы игнорируются.

В стандартный поток вывода выводится время разбиения сетки в секундах
(берётся максимальное значение среди всех процессоров).

\chapter*{Используемая вычислительная система}

Вычисления проводились на системе IBM Blue Gene/P.
Характеристики системы представлены на сайте~\cite{bluegene}.

Система состоит из двух стоек, включающих 8192 процессорных ядер
(2*1024 четырехъядерных вычислительных узлов), с пиковой производительностью
27,9 терафлопс (27,8528 триллионов операций с плавающей точкой в секунду).

Характеристики вычислительного узла:

\begin{itemize}
    \item четыре микропроцессорных ядра;
    \item пиковая производительность: 13,6 ГФлопс;
    \item пропускная способность памяти: 13,6 ГБ/с;
    \item 2 ГБ общей памяти;
    \item 2 * 4 МБ кэш-памяти 2-го уровня;
    \item легковесное ядро, представляющее собой Linux-подобную операционную систему,
        поддерживающую значительное подмножество Linux-совместимых системных вызовов;
    \item асинхронные операции межпроцессорных обменов (выполняются параллельно с вычислениями);
    \item операции ввода-вывода перенаправляются I/O-картам через сеть коллективных операций;
    \item MPI-операции типа «точка-точка» осуществляются через сеть трехмерного тора.
        \begin{itemize}
            \item Вычислительный узел имеет двунаправленные связи с шестью соседями.
            \item Пропускная способность каждого соединения — 425 МБ/с (5,1 ГБ/с для всех 12
        каналов).
            \item Латентность (ближайший сосед):
                \begin{itemize}
                    \item 32-байтный пакет~--- 0,1 мкс.
                    \item 256-байтный пакет~--- 0,8 мкс.
                \end{itemize}
        \end{itemize}
\end{itemize}


\chapter*{Анализ полученных результатов}

\section*{Прямоугольная сетка}

Тестирование проводилось на прямоугольной сетке размером
1000*1000 (разбиение на 5000 доменов), 2000*2000 (10000 доменов) и
4000*4000 (50000 доменов) на 32, 64, 128 и 256 процессорах. Число разрезанных
рёбер равно 193356, 577864 и
2758454 соответственно. Время работы программы, ускорение и эффективность
распараллеливания приведены в таблицах \ref{tab1000}, \ref{tab2000},
\ref{tab4000}.

Ускорение и эффективность рассчитывались по формулам:
$S_p = \frac{T_1}{T_p}, E_p = \frac{S_p}{p} = \frac{T_1}{p * T_p}$, где
$T_1$~--- время работы последовательного алгоритма,
$T_p$~--- время работы параллельного алгоритма на $p$ процессорах.

\begin{table}[h]
\centering
\begin{tabular}{|r|r|r|r|}\hline
$p$    & $T_p$, сек. & $S_p$ & $E_p$ \\ \hline
1      & 6.78        &       &       \\ \hline
32     & 0.345015    & 19.65 & 0.61  \\ \hline
64     & 0.261421    & 25.93 & 0.40  \\ \hline
128    & 0.204421    & 33.16 & 0.25  \\ \hline
256    & 0.157027    & 43.17 & 0.16  \\ \hline
\end{tabular}
\caption{Результаты работы при разбиении сетки 1000*1000 на 5000 доменов}
\label{tab1000}
\end{table}

\begin{table}[h]
\centering
\begin{tabular}{|r|r|r|r|}\hline
$p$    & $T_p$, сек. & $S_p$ & $E_p$ \\ \hline
1      & 32.56       &       &       \\ \hline
32     & 1.505918    & 21.62 & 0.67  \\ \hline
64     & 0.90615     & 35.93 & 0.56  \\ \hline
128    & 0.67891     & 47.95 & 0.37  \\ \hline
256    & 0.470043    & 69.27 & 0.27  \\ \hline
\end{tabular}
\caption{Результаты работы при разбиении сетки 2000*2000 на 10000 доменов}
\label{tab2000}
\end{table}

\begin{table}[h]
\centering
\begin{tabular}{|r|r|r|r|}\hline
$p$    & $T_p$, сек. & $S_p$ & $E_p$ \\ \hline
1      & 160.38      &       &       \\ \hline
32     & 7.882935    & 20.34 & 0.63  \\ \hline
64     & 4.063828    & 39.46 & 0.61  \\ \hline
128    & 3.102539    & 51.69 & 0.40  \\ \hline
256    & 1.974635    & 81.22 & 0.31  \\ \hline
\end{tabular}
\caption{Результаты работы при разбиении сетки 4000*4000 на 50000 доменов}
\label{tab4000}
\end{table}

\newpage
\section*{Спиралевидная сетка}

\begin{thebibliography}{0}
\addcontentsline{toc}{chapter}{Литература}
    \bibitem{baraban}
        М.\,В.~Якобовский.
        Введение в параллельные методы решения задач: Учебное пособие / Предисл.: В.\,А.~Садовничий.
        М.: Издательство Московского университета, 2013.

    \bibitem{sortbaraban}
        М.\,В.~Якобовский.
        Параллельные алгоритмы сортировки больших объемов данных.
        2004, 2008.

    \bibitem{bluegene}
        Описание вычислительного комплекса IBM Blue Gene/P.
        http://hpc.cmc.msu.ru/bgp
\end{thebibliography}

\newpage
\appendix
\chapter{Последовательный алгоритм декомпозиции} \label{app:seq}
\begin{verbatim}
// File bisect_seq.cpp

#include <stdio.h>
#include <time.h>
#include <stdlib.h>
#include <unistd.h>
#include <string.h>

bool axis = true;

struct Point {
    float coord[2];
    int index;
    int domain;
};

float x(int i, int j)
{
    return 10*(float)rand()/(float)(RAND_MAX/(i*j+1));
}

float y(int i, int j)
{
    return 10*(float)rand()/(float)(RAND_MAX/(i*j+1));
}

bool check_args(int argc, char **argv, int &nx, int &ny, int &k)
{
    if (argc < 4) {
        printf("Wrong arguments."
               "Usage: bisect_seq nx ny k [output]\n");
        return false;
    }
    int check = sscanf(argv[1], "%d", &nx);
    if (!check) {
        printf("nx must be int: %s\n", argv[1]);
        return false;
    }
    check = sscanf(argv[2], "%d", &ny);
    if (!check) {
        printf("ny must be int: %s\n", argv[2]);
        return false;
    }
    check = sscanf(argv[3], "%d", &k);
    if (!check) {
        printf("k must be int: %s\n", argv[3]);
        return false;
    }
    if (!((nx >= 1) && (ny >= 1) && (k >= 1))) {
        printf("Wrong nx or nx or k\n");
        return false;
    }
    return true;
}

Point* init_points(int n, int ny, int procs, int proc_elems, int rank)
{
    Point *res = new Point[proc_elems];
    int tmp = n/procs;
    int not_fake = n % procs;
    int real_elems = rank < not_fake ? tmp + 1 : tmp;
    int delta;
    if (rank < not_fake)
        delta = rank*proc_elems;
    else
        delta = not_fake*proc_elems + tmp*(rank - not_fake);
    for (int k = 0; k < real_elems; k++) {
        int i = (k + delta) / ny, j = (k + delta) % ny;
        Point p;
        p.coord[0] = x(i, j);
        p.coord[1] = y(i, j);
        p.index = i*ny + j;
        p.domain = -1;
        res[k] = p;
    }
    return res;
}

inline int compare_points(const void *a, const void *b)
{
    Point *aptr = (Point * const)a;
    Point *bptr = (Point * const)b;
    int c = axis ? 0 : 1;
    float ax = aptr->coord[c];
    float bx = bptr->coord[c];

    if (ax == bx)
        return 0;
    else if (ax > bx)
        return 1;
    return -1;
}

void dsort(Point *array, int n, int sorted)
{
    Point *a = array;
    Point *b = new Point[n];
    Point *c;

    for (int i = sorted; i < n ; i *= 2) {
        for (int j = 0; j < n; j = j + 2*i) {
            int r = j + i;

            int n1 = (i < n - j) ? i : n - j;
            int n2 = (i < n - r) ? i : n - r;
            n1 = (n1 < 0) ? 0 : n1;
            n2 = (n2 < 0) ? 0 : n2;

            for (int ia = 0, ib = 0, k = 0; k < n1 + n2; k++) {
                if (ia >= n1)
                    b[j+k] = a[r+ib++];
                else if (ib >= n2)
                    b[j+k]=a[j+ia++];
                else if (compare_points(&a[j+ia], &a[r+ib]) < 0)
                    b[j+k]=a[j+ia++];
                else
                    b[j+k]=a[r+ib++];
            }
        }
        c = a;
        a = b;
        b = c;
    }

    c = a;
    a = b;
    b = c;
    if (b != array) {
        memcpy(array, b, n*sizeof(*array));
        delete [] b;
    } else {
        delete [] a;
    }
}

void print_domains(Point *points, int n, int ny)
{
    for (int i = 0; i < n; i++) {
      Point cur = points[i];
      printf("%d %d %f %f %d\n", cur.index / ny, cur.index % ny,
             cur.coord[0], cur.coord[1], cur.domain);
    }
}

void bisect(Point *points, int n0, int n, int dom0, int k)
{
    // One point
    if (n == 1) {
      points[n0].domain = dom0;
      return;
    }

    // One domain
    if (k == 1) {
      for (int i = 0; i < n; i++)
        points[n0 + i].domain = dom0;
      return;
    }

    // Sort and change axis
    dsort(points + n0, n, 1);
    axis = !axis;

    // Split ratio
    int k1 = (k + 1) / 2;
    int k2 = k - k1;
    int n1 = n*(k1/(double)k);
    int n2 = n - n1;

    // Recursively split parts
    bisect(points, n0, n1, dom0, k1);
    bisect(points, n0 + n1, n2, dom0 + k1, k2);
}

bool connected(Point p1, Point p2, int ny)
{
    int i1 = p1.index / ny;
    int j1 = p1.index % ny;
    int i2 = p2.index / ny;
    int j2 = p2.index % ny;
    return (((i1 == i2) && (abs(j1 - j2) == 1)) ||
            ((j1 == j2) && (abs(i1 - i2) == 1)));
}

int edges(Point *p, int n, int ny)
{
    int res = 0;
    for (int i = p[0].domain, j = 0; j < n; i++)
        for (; p[j].domain == i && j < n; j++) {
            Point p1 = p[j];
            for (int k = j + 1; p[k].domain == i && k < n; k++) {
                Point p2 = p[k];
                if (connected(p1, p2, ny))
                    res++;
            }
        }
    return res;
}

void write_to_file(const char *path, Point *p, int n, int ny)
{
    FILE *fd = fopen(path, "w");
    if (fd) {
        for (int i = 0; i < n; i++) {
          Point cur = p[i];
          fprintf(fd, "%d %d %f %f %d\n", cur.index / ny,
                  cur.index % ny, cur.coord[0], cur.coord[1],
                  cur.domain);
        }
        printf("Results written to %s\n", path);
    } else {
        perror(path);
        exit(2);
    }
}

int main(int argc, char **argv)
{
    int nx, ny, k;

    // Parsing command line arguments
    if (!check_args(argc, argv, nx, ny, k))
      return 1;

    int n = nx*ny;
    srand(time(NULL));
    Point *points = init_points(n, ny, 1, n, 0);

    clock_t t = clock();
    bisect(points, 0, n, 0, k);
    t = clock() - t;

    printf("Decomposition time: %lf sec.\n",
           (double)t/CLOCKS_PER_SEC);

    int total_edges = nx*(ny - 1) + ny*(nx - 1);
    int cut = total_edges - edges(points, n, ny);
    printf("Edges cut: %d of %d\n", cut, total_edges);

    if (argc >= 5)
        write_to_file(argv[4], points, n, ny);
    return 0;
}

\end{verbatim}

\chapter{Параллельный алгоритм декомпозиции} \label{app:par}
\begin{verbatim}
// File bisect.cpp
#include <stdio.h>
#include <stdlib.h>
#include <mpi.h>
#include <time.h>
#include <string.h>
#include <cmath>
#include <vector>
#include <cstddef>
#include <float.h>

bool axis = true;
int *domain_array;
MPI_Datatype MPI_POINT;

struct Domain {
    int i;
    int j;
    float coord[2];
    int domain;
};

struct Point {
    float coord[2];
    int index;
};

float x(int i, int j)
{
    return 10*(float)rand()/(float)(RAND_MAX/(i*j+1));
}

float y(int i, int j)
{
    return 10*(float)rand()/(float)(RAND_MAX/(i*j+1));
}

Point* init_points(int n, int ny, int procs, int proc_elems, int rank)
{
    Point *res = new Point[proc_elems];
    int tmp = n/procs;
    int not_fake = n % procs;
    int real_elems = rank < not_fake ? tmp + 1 : tmp;
    int delta;
    if (rank < not_fake)
        delta = rank*proc_elems;
    else
        delta = not_fake*proc_elems + tmp*(rank - not_fake);
    for (int k = 0; k < real_elems; k++) {
        int i = (k + delta) / ny, j = (k + delta) % ny;
        Point p;
        p.coord[0] = x(i, j);
        p.coord[1] = y(i, j);
        p.index = i*ny + j;
        res[k] = p;
    }
    for (int k = real_elems; k < proc_elems; k++) {
        Point p;
        p.coord[0] = FLT_MAX;
        p.coord[1] = FLT_MAX;
        p.index = -1;
        res[k] = p;
    }

    return res;
}

MPI_Datatype pointType()
{
    MPI_Datatype point;
    MPI_Datatype types[2] = { MPI_FLOAT, MPI_INT };
    int blocks[2] = { 2, 1 };
    MPI_Aint disps[2] = { offsetof(Point, coord),
                          offsetof(Point, index) };
    MPI_Type_create_struct(2, blocks, disps, types, &point);
    MPI_Type_commit(&point);
    return point;
}

typedef std::pair<int, int> comparator;

void swap(comparator cmp, std::vector<int> &v)
{
    int fst = cmp.first;
    int snd = cmp.second;
    if (v[fst] > v[snd]) {
        int tmp = v[fst];
        v[fst] = v[snd];
        v[snd] = tmp;
    }
}

bool check_args(int argc, char **argv, int &nx, int &ny, int &k)
{
    if (argc < 4) {
        printf("Wrong arguments. Usage: bisect nx ny k [output]\n");
        return false;
    }
    int check = sscanf(argv[1], "%d", &nx);
    if (!check) {
        printf("nx must be int: %s\n", argv[1]);
        return false;
    }
    check = sscanf(argv[2], "%d", &ny);
    if (!check) {
        printf("ny must be int: %s\n", argv[2]);
        return false;
    }
    check = sscanf(argv[3], "%d", &k);
    if (!check) {
        printf("k must be int: %s\n", argv[3]);
        return false;
    }
    if (!((nx >= 1) && (ny >= 1) && (k >= 1))) {
        printf("Wrong nx or nx or k\n");
        return false;
    }
    return true;
}

void swap_ptr(void *ptr1_ptr, void *ptr2_ptr)
{
    void **ptr1 = (void **)ptr1_ptr;
    void **ptr2 = (void **)ptr2_ptr;

    void *tmp = *ptr1;
    *ptr1 = *ptr2;
    *ptr2 = tmp;
}

inline int compare_points(const void *a, const void *b)
{
    Point *aptr = (Point * const)a;
    Point *bptr = (Point * const)b;
    int c = axis ? 0 : 1;
    float ax = aptr->coord[c];
    float bx = bptr->coord[c];

    if (ax == bx)
        return 0;
    else if (ax > bx)
        return 1;
    return -1;
}

void dsort(Point *array, int n, int sorted)
{
    Point *a = array;
    Point *b = new Point[n];
    Point *c;

    for (int i = sorted; i < n ; i *= 2) {
        for (int j = 0; j < n; j = j + 2*i) {
            int r = j + i;

            int n1 = (i < n - j) ? i : n - j;
            int n2 = (i < n - r) ? i : n - r;
            n1 = (n1 < 0) ? 0 : n1;
            n2 = (n2 < 0) ? 0 : n2;

            for (int ia = 0, ib = 0, k = 0; k < n1 + n2; k++) {
                if (ia >= n1)
                    b[j+k] = a[r+ib++];
                else if (ib >= n2)
                    b[j+k]=a[j+ia++];
                else if (compare_points(&a[j+ia], &a[r+ib]) < 0)
                    b[j+k]=a[j+ia++];
                else
                    b[j+k]=a[r+ib++];
            }
        }
        c = a;
        a = b;
        b = c;
    }

    c = a;
    a = b;
    b = c;
    if (b != array) {
        memcpy(array, b, n*sizeof(*array));
        delete [] b;
    } else {
        delete [] a;
    }
}

void join(std::vector<int> idx_up, int n0, std::vector<int> idx_down,
          int n1, std::vector<comparator> &cmp)
{
    int n = n0 + n1;
    if (n == 1)
        return;

    if (n0 == 1 && n1 == 1) {
        cmp.push_back(comparator(idx_up[0], idx_down[0]));
        return;
    }

    int n0_even = n0/2;
    int n0_odd = n0 - n0_even;
    std::vector<int> idx_up_even(n0_even);
    std::vector<int> idx_up_odd(n0_odd);

    int n1_even = n1/2;
    int n1_odd = n1 - n1_even;
    std::vector<int> idx_down_even(n1_even);
    std::vector<int> idx_down_odd(n1_odd);

    std::vector<int> idx_result;

    int i, i0 = 0, i1 = 0;
    for (i = 0; i < n0; i++)
        if (i%2) {
            idx_up_even[i0] = idx_up[i];
            i0++;
        } else {
            idx_up_odd[i1] = idx_up[i];
            i1++;
        }
    i0 = i1 = 0;
    for (i = 0; i < n1; i++)
        if (i%2) {
            idx_down_even[i0] = idx_down[i];
            i0++;
        } else {
            idx_down_odd[i1] = idx_down[i];
            i1++;
        }

    join(idx_up_odd, n0_odd, idx_down_odd, n1_odd, cmp);
    join(idx_up_even, n0_even, idx_down_even, n1_even, cmp);

    for (i = 0; i < n0; i++)
        idx_result.push_back(idx_up[i]);
    for (i = 0; i < n1; i++)
        idx_result.push_back(idx_down[i]);

    for (int i = 1; i < n - 1; i += 2)
        cmp.push_back(comparator(idx_result[i], idx_result[i + 1]));
}

void sort(std::vector<int>idx, int n, std::vector<comparator> &cmp)
{
    if (n == 1) {
        return;
    }

    int n0 = n/2;
    int n1 = n - n0;

    std::vector<int> idx_up;
    std::vector<int> idx_down;

    int i;
    for (i = 0; i < n0; i++)
        idx_up.push_back(idx[i]);
    for (i = n0; i < n; i++)
        idx_down.push_back(idx[i]);

    sort(idx_up, n0, cmp);
    sort(idx_down, n1, cmp);
    join(idx_up, n0, idx_down, n1, cmp);
}

void make_comparators(int procs, std::vector<comparator> &cmp)
{
    std::vector<int> idx;
    for (int i = 0; i < procs; i++)
        idx.push_back(i);
    sort(idx, procs, cmp);
    return;
}

void batcher(Point* &proc_points, int proc_elems,
             std::vector<comparator> cmp, MPI_Comm comm)
{
    dsort(proc_points, proc_elems, 1);

    // Exchanging elements
    Point *tmp_points = new Point[proc_elems];
    Point *other_points = new Point[proc_elems];
    int rank;
    MPI_Comm_rank(comm, &rank);
    MPI_Status status;
    std::vector<comparator>::iterator it;
    for (it = cmp.begin(); it != cmp.end(); it++) {
        if (rank == it->first) {
            MPI_Send(proc_points, proc_elems, MPI_POINT,
                     it->second, 0, comm);
            MPI_Recv(other_points, proc_elems, MPI_POINT,
                     it->second, 0, comm, &status);
            int idx = 0;
            int other_idx = 0;
            for (int tmp_idx = 0; tmp_idx < proc_elems; tmp_idx++) {
                Point my = proc_points[idx];
                Point other = other_points[other_idx];
                if (my.coord[0] < other.coord[0]) {
                    tmp_points[tmp_idx] = my;
                    idx++;
                } else {
                    tmp_points[tmp_idx] = other;
                    other_idx++;
                }
            }
            swap_ptr(&proc_points, &tmp_points);
        }

        if (rank == it->second) {
            MPI_Recv(other_points, proc_elems, MPI_POINT,
                     it->first, 0, comm, &status);
            MPI_Send(proc_points, proc_elems, MPI_POINT,
                     it->first, 0, comm);
            int idx = proc_elems - 1;
            int other_idx = proc_elems - 1;
            for (int tmp_idx = other_idx; tmp_idx >= 0; tmp_idx--) {
                Point my = proc_points[idx];
                Point other = other_points[other_idx];
                if (my.coord[0] > other.coord[0]) {
                    tmp_points[tmp_idx] = my;
                    idx--;
                } else {
                    tmp_points[tmp_idx] = other;
                    other_idx--;
                }
            }
            swap_ptr(&proc_points, &tmp_points);
        }
    }
}

void bisect_seq(Point *points, int n0, int n, int dom0, int k)
{
    // One point
    if (n == 1) {
      domain_array[n0] = dom0;
      return;
    }

    // One domain
    if (k == 1) {
      for (int i = 0; i < n; i++)
        domain_array[n0 + i] = dom0;
      return;
    }

    // Sort and change axis
    dsort(points + n0, n, 1);
    axis = !axis;

    // Split ratio
    int k1 = (k + 1) / 2;
    int k2 = k - k1;
    int n1 = n*(k1/(double)k);
    int n2 = n - n1;

    // Recursively bisect parts
    bisect_seq(points, n0, n1, dom0, k1);
    bisect_seq(points, n0 + n1, n2, dom0 + k1, k2);
}

int remove_fake(Point **points, int n)
{
    Point *res_points = new Point[n];
    int res_n = 0;
    for (int i = 0; i < n; i++) {
        if ((*points)[i].index != -1)
          res_points[res_n++] = (*points)[i];
    }
    delete [] (*points);
    *points = res_points;
    return res_n;
}

double min_coord(Point *points, int n, int c)
{
    double res = FLT_MAX;
    for (int i = 0; i < n; i++)
      if ((points[i].index != -1) && (points[i].coord[c] < res))
        res = points[i].coord[c];
    return res;
}

double max_coord(Point *points, int n, int c)
{
    double res = FLT_MIN;
    for (int i = 0; i < n; i++)
      if ((points[i].index != -1) && (points[i].coord[c] > res))
        res = points[i].coord[c];
    return res;
}

void change_axis(Point *points, int n, MPI_Comm comm)
{
    double local_minx = min_coord(points, n, 0);
    double local_miny = min_coord(points, n, 1);
    double local_maxx = max_coord(points, n, 0);
    double local_maxy = max_coord(points, n, 1);
    double minx = 0, miny = 0, maxx = 0, maxy = 0;
    MPI_Allreduce(&local_minx, &minx, 1, MPI_DOUBLE, MPI_MIN, comm);
    MPI_Allreduce(&local_miny, &miny, 1, MPI_DOUBLE, MPI_MIN, comm);
    MPI_Allreduce(&local_maxx, &maxx, 1, MPI_DOUBLE, MPI_MAX, comm);
    MPI_Allreduce(&local_maxy, &maxy, 1, MPI_DOUBLE, MPI_MAX, comm);
    double dx = maxx - minx, dy = maxy - miny;
    axis = dx <= dy;
}

Point *add_fake(Point *points, int n, int procs)
{
    int proc_elems = ceil(n/(double)procs);
    Point *res = new Point[procs*proc_elems];
    int idx = 0;
    for (int i = 0; i < n; i++, idx++) {
        res[idx] = points[i];
        points[i].index = -1;
        points[i].coord[0] = FLT_MAX;
        points[i].coord[1] = FLT_MAX;
    }
    for (; idx < procs*proc_elems; idx++) {
        res[idx].index = -1;
        res[idx].coord[0] = FLT_MAX;
        res[idx].coord[1] = FLT_MAX;
    }
    return res;
}

void bisect(Point **points, int &proc_elems, int n, int k, int dom0,
            MPI_Comm comm)
{
    // One domain
    if (k == 1) {
        int real_elems = remove_fake(points, proc_elems);
        domain_array = new int[real_elems];
        for (int i = 0; i < real_elems; i++)
            domain_array[i] = dom0;
        proc_elems = real_elems;
        return;
    }

    int rank, procs;
    MPI_Comm_rank(comm, &rank);
    MPI_Comm_size(comm, &procs);

    // One proc
    if (procs == 1) {
        int real_elems = remove_fake(points, proc_elems);
        domain_array = new int[real_elems];
        bisect_seq(*points, 0, real_elems, dom0, k);
        proc_elems = real_elems;
        return;
    }

    // Split ratio
    int k1 = (k + 1) / 2;
    int k2 = k - k1;
    int n1 = n*(k1/(double)k);
    int n2 = n - n1;
    int middle = n1 % proc_elems;
    int procs1 = n1 / proc_elems; // on the left
    int psplit = procs1 ? (rank >= procs1 ? 0 : 1) :
                          (rank > procs1 ? 0 : 1);

    change_axis(*points, proc_elems, comm);

    // Sort
    std::vector<comparator> cmp;
    make_comparators(procs, cmp);
    batcher(*points, proc_elems, cmp, comm);

    // Split procs
    MPI_Comm comm_split;
    MPI_Comm_split(comm, psplit, rank, &comm_split);

    // Rearrange elements on edges for recursive call
    MPI_Status s;
    if (procs1) {
        if (rank <= procs1) {
            int proc_elems1 = ceil(middle/(double)procs1);
            if (rank == procs1) { // send to the left
                Point *tmp = add_fake(*points, middle, procs1);
                for (int i = 0; i < procs1; i++)
                    MPI_Send(tmp + i*proc_elems1, proc_elems1,
                             MPI_POINT, i, 0, comm);
                delete [] tmp;
                bisect(points, proc_elems, n2, k2,
                       dom0 + k1, comm_split);
            } else { // recieve new elems
                Point *other = new Point[proc_elems + proc_elems1];
                MPI_Recv(other + proc_elems, proc_elems1, MPI_POINT,
                         procs1, 0, comm, &s);
                memcpy(other, *points, proc_elems * sizeof(Point));
                proc_elems += proc_elems1;
                delete [] (*points);
                *points = other;
                bisect(points, proc_elems, n1, k1, dom0, comm_split);
            }
        } else { // nothing to exchange, just decompose
            bisect(points, proc_elems, n2, k2, dom0 + k1, comm_split);
        }
    } else { // we'll have to send some to the right
        int proc_elems1 =
            ceil((proc_elems - middle)/(double)(procs - procs1));
        if (rank) { // recieve new elems
            Point *other = new Point[proc_elems + proc_elems1];
            MPI_Recv(other + proc_elems, proc_elems1, MPI_POINT,
                     procs1, 0, comm, &s);
            memcpy(other, *points, proc_elems * sizeof(Point));
            proc_elems += proc_elems1;
            delete [] (*points);
            *points = other;
            bisect(points, proc_elems, n2, k2, dom0 + k1, comm_split);
        } else { //rank == 0
            Point *tmp = add_fake(*points + middle,
                                  proc_elems - middle,
                                  procs - procs1 - 1);
            for (int i = procs1 + 1, j = 0; i < procs; i++, j++)
                MPI_Send(tmp + j*proc_elems1, proc_elems1, MPI_POINT,
                         i, 0, comm);
            delete [] tmp;
            bisect(points, proc_elems, n1, k1, dom0, comm_split);
        }
    }
}

bool connected(Domain p1, Domain p2, int ny)
{
    int i1 = p1.i;
    int j1 = p1.j;
    int i2 = p2.i;
    int j2 = p2.j;
    return (((i1 == i2) && (abs(j1 - j2) == 1)) ||
            ((j1 == j2) && (abs(i1 - i2) == 1)));
}

int edges(Domain *p, int n, int ny)
{
    int res = 0;
    for (int i = p[0].domain, j = 0; j < n; i++)
        for (; p[j].domain == i && j < n; j++) {
            Domain p1 = p[j];
            for (int k = j + 1; p[k].domain == i && k < n; k++) {
                Domain p2 = p[k];
                if (connected(p1, p2, ny))
                    res++;
            }
        }
    return res;
}

void write_to_file(const char *path, Domain *arr, int n,
                   int nx, int ny, int k, int cut, int rank)
{
    MPI_File fd;
    if (MPI_File_open(MPI_COMM_WORLD, path,
                      MPI_MODE_CREATE | MPI_MODE_WRONLY,
                      MPI_INFO_NULL, &fd) != MPI_SUCCESS) {
        if (!rank)
            printf("Cannot open file %s\n", path);
        MPI_Finalize();
        exit(2);
    }
    MPI_File_set_size(fd, 0);

    MPI_Datatype MPI_DOMAIN;
    MPI_Datatype types[4] = { MPI_INT, MPI_INT, MPI_FLOAT, MPI_INT };
    int blocks[4] = { 1, 1, 2, 1 };
    MPI_Aint disps[4] = { offsetof(Domain, i),
                          offsetof(Domain, j),
                          offsetof(Domain, coord),
                          offsetof(Domain, domain) };
    MPI_Type_create_struct(4, blocks, disps, types, &MPI_DOMAIN);
    MPI_Type_commit(&MPI_DOMAIN);

    MPI_Status s;
    MPI_File_write_ordered(fd, &nx, !rank, MPI_INT, &s);
    MPI_File_write_ordered(fd, &ny, !rank, MPI_INT, &s);
    MPI_File_write_ordered(fd, &k, !rank, MPI_INT, &s);
    MPI_File_write_ordered(fd, &cut, !rank, MPI_INT, &s);
    MPI_File_write_ordered(fd, arr, n, MPI_DOMAIN, &s);

    MPI_File_close(&fd);
}

int main(int argc, char **argv)
{
    int nx, ny, k;

    // Parsing command line arguments
    if (!check_args(argc, argv, nx, ny, k))
        return 1;

    MPI_Init(&argc, &argv);

    int rank, procs;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &procs);

    if (k < procs) {
        printf("k should be >= procs");
        return 1;
    }

    // Calculating elems per processor
    int n = nx*ny;
    int fake = n % procs ? (procs - n % procs) : 0;
    int elems = n + fake;
    int proc_elems = elems / procs;

    // Initializing points
    srand(time(NULL) + rank);
    Point *proc_points =
        init_points(n, ny, procs, proc_elems, rank);

    // Decomposition
    MPI_POINT = pointType();
    double start_time = MPI_Wtime();
    bisect(&proc_points, proc_elems, n, k, 0, MPI_COMM_WORLD);
    double end_time = MPI_Wtime();
    double time = end_time - start_time;
    double max_time = 0;
    MPI_Reduce(&time, &max_time, 1, MPI_FLOAT,
               MPI_MAX, 0, MPI_COMM_WORLD);

    if (!rank)
        printf("Decomposition time: %f sec.\n", max_time);

    // Remove fake
    Domain *proc_domains = new Domain[proc_elems];
    int new_proc_elems = 0;
    for (int i = 0; i < proc_elems; i++) {
        if (proc_points[i].index != -1) {
            proc_domains[new_proc_elems].i =
                proc_points[i].index / ny;
            proc_domains[new_proc_elems].j =
                proc_points[i].index % ny;
            proc_domains[new_proc_elems].coord[0] =
                proc_points[i].coord[0];
            proc_domains[new_proc_elems].coord[1] =
                proc_points[i].coord[1];
            proc_domains[new_proc_elems++].domain =
                domain_array[i];
        }
    }

    // Cut edges
    int total_edges = nx*(ny - 1) + ny*(nx - 1);
    int local_edges = edges(proc_domains, new_proc_elems, ny);
    int sum_edges = 0;
    MPI_Reduce(&local_edges, &sum_edges, 1, MPI_INT,
               MPI_SUM, 0, MPI_COMM_WORLD);
    int cut = total_edges - sum_edges;

    if (argc >= 5)
        write_to_file(argv[4], proc_domains, new_proc_elems,
                      nx, ny, k, cut, rank);

    delete [] proc_points;
    delete [] proc_domains;
    delete [] domain_array;
    MPI_Finalize();
    return 0;
}

\end{verbatim}

\end{document}


